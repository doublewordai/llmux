diff --git a/vllm/model_executor/utils.py b/vllm/model_executor/utils.py
index d4e87707c..487c0554e 100644
--- a/vllm/model_executor/utils.py
+++ b/vllm/model_executor/utils.py
@@ -62,9 +62,16 @@ def replace_parameter(layer: torch.nn.Module, param_name: str, new_data: torch.T
     new_param = torch.nn.Parameter(new_data, requires_grad=False)
 
     old_param: torch.nn.Parameter | None = getattr(layer, param_name, None)
-    if old_param is not None and hasattr(old_param, "weight_loader"):
-        weight_loader = old_param.weight_loader
-        set_weight_attrs(new_param, {"weight_loader": weight_loader})
+    if old_param is not None:
+        # Preserve the parameter subclass (e.g. RowvLLMParameter,
+        # ModelWeightParameter) so that methods like
+        # load_row_parallel_weight survive reload_weights.
+        new_param.__class__ = old_param.__class__
+        # Copy all instance attributes (weight_loader, output_dim, etc.)
+        # from the old parameter to the new one.
+        for attr, value in old_param.__dict__.items():
+            if attr not in ("data",):
+                setattr(new_param, attr, value)
 
     setattr(layer, param_name, new_param)
 
